services:
  auth_db:
    image: postgres:15
    restart: always
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - pgdata_users:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${DB_USER}", "-d", "${DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - users_network

  posts_db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_DB: ${DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    ports:
      - "5434:5432"
    volumes:
      - pgdata_posts:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${DATABASE_USER}", "-d", "${DATABASE_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - posts_network

  gateway_api:
    build:
      context: .
      dockerfile: ./services/gateway/Dockerfile
    env_file:
      - .env
    depends_on:
      auth:
          condition: service_healthy
      posts:
          condition: service_healthy
      kafka:
        condition: service_healthy
      statistics:
        condition: service_healthy
    ports:
      - "5000:5000"
    volumes:
      - ./services/gateway:/gateway
    networks:
      - proxy_network
      - users_network
      - posts_network
      - kafka_network

  auth:
    build: 
        context: .
        dockerfile: services/users/Dockerfile
    depends_on:
      auth_db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "8090:8090"
    volumes:
      - ./services/users:/users
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 5s
      retries: 5
      timeout: 3s
    networks:
      - proxy_network
      - users_network
      - kafka_network
  
  posts:
    build:
      context: services/posts/service
      dockerfile: server.dockerfile
    depends_on:
      posts_db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "8091:8091"
    healthcheck:
      test: ["CMD", "true"]
      interval: 5s
    networks:
      - proxy_network
      - posts_network
      - kafka_network

  tests:
    build:
        context: .
        dockerfile: ./services/tests/Dockerfile
    env_file:
      - .env
    depends_on:
      - gateway_api
      - kafka
    volumes:
      - ./services/tests:/tests
      - ./services/posts:/tests/posts
      - ./services/statistics/statistics_pb2_grpc.py:/tests/posts/service/proto/statistics_pb2_grpc.py
      - ./services/statistics/statistics_pb2.py:/tests/posts/service/proto/statistics_pb2.py
      - ./services/broker/kafka_producer.py:/tests/kafka_producer.py
    networks:
      - proxy_network
      - kafka_network
  
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - kafka_network

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_HOSTNAME: kafka
    networks:
      - kafka_network
    healthcheck:
      test: kafka-topics --bootstrap-server localhost:9092 --list || exit 1
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
  
  kafka-setup:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka
    command: >
      bash -c "
        cub kafka-ready -b kafka:29092 1 30 &&
        kafka-topics --create --if-not-exists --topic client_registrations --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 &&
        kafka-topics --create --if-not-exists --topic posts_likes --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 &&
        kafka-topics --create --if-not-exists --topic posts_views --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 &&
        kafka-topics --create --if-not-exists --topic posts_comments --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1
      "
    networks:
      - kafka_network
  
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 5s
      timeout: 5s
      retries: 5
    env_file:
      - .env
    environment:
      CLICKHOUSE_DB: statistics
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}

  clickhouse-setup:
    image: clickhouse/clickhouse-client:latest
    depends_on:
      clickhouse:
        condition: service_healthy
    entrypoint: ["bash", "-c"]
    env_file:
      - .env
    command: >
      "
      until clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --query 'SELECT 1'; do
        echo 'Waiting for ClickHouse server...';
        sleep 2;
      done;

      echo 'Creating database and tables...';

      clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --query \"
        CREATE DATABASE IF NOT EXISTS statistics;
      \";

      clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --query \"
        CREATE TABLE IF NOT EXISTS statistics.post_views (
          post_id UUID,
          user_id UUID,
          view_date Date,
          view_time DateTime,
          view_timestamp DateTime DEFAULT now()
        ) ENGINE = MergeTree()
        ORDER BY (post_id, view_date, view_time);
      \";

      clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --query \"
        CREATE TABLE IF NOT EXISTS statistics.post_likes (
          post_id UUID,
          user_id UUID,
          like_date Date,
          like_time DateTime,
          like_timestamp DateTime DEFAULT now(),
          is_like UInt8
        ) ENGINE = MergeTree()
        ORDER BY (post_id, like_date, like_time);
      \";

      clickhouse-client --host clickhouse --user ${CLICKHOUSE_USER} --password ${CLICKHOUSE_PASSWORD} --query \"
        CREATE TABLE IF NOT EXISTS statistics.post_comments (
          post_id UUID,
          user_id UUID,
          comment_id UUID,
          comment_date Date,
          comment_time DateTime,
          comment_timestamp DateTime DEFAULT now()
        ) ENGINE = MergeTree()
        ORDER BY (post_id, comment_date, comment_time);
      \";

      echo 'ClickHouse initialization complete.';
      "
    networks:
      - kafka_network
  
  statistics:
    build:
      context: .
      dockerfile: ./services/statistics/Dockerfile
    depends_on:
      clickhouse:
        condition: service_healthy
      kafka:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "8092:8092"
    volumes:
      - ./services/statistics:/statistics
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "true"]
      interval: 5s


networks:
  posts_network:
    driver: bridge
  users_network:
    driver: bridge
  proxy_network:
    driver: bridge
  kafka_network:
    driver: bridge

volumes:
  pgdata_users:
  pgdata_posts:
  clickhouse_data: